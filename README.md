# QuickToken

A fast, beautiful CLI tool to count tokens in files using GPT tokenizers.

## Installation

```bash
# Clone the repository
git clone https://github.com/patrickmcrawley/quicktoken.git
cd quicktoken

# Install with uv (recommended)
uv sync
uv pip install -e .
```

## Usage

```bash
# Count tokens in a file
quicktoken my-file.md

# Use a different model tokenizer
quicktoken --model gpt-3.5-turbo my-file.txt

# Get help
quicktoken --help
```

## Example Output

```
ğŸ“„ example.md
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¢ Tokens:      1,234
ğŸ“ Characters:  5,678
ğŸ“ Lines:       42
ğŸ’¾ File size:   5.5 KB
âš¡ Ratio:       0.217 tokens/char
ğŸ¤– Model:       gpt-4o
```

## Features

- âš¡ Fast token counting using tiktoken
- ğŸ¨ Beautiful, colorized output
- ğŸ“Š Comprehensive file statistics
- ğŸ¤– Support for different model tokenizers
- ğŸ’» Works on macOS and Linux
- ğŸ“„ Handles any UTF-8 text file

## Supported Models

- `gpt-4o` (default)
- `gpt-4`
- `gpt-3.5-turbo`
- And any other model supported by tiktoken

## Requirements

- Python 3.12+
- tiktoken

## Development

This project uses `uv` for dependency management:

```bash
# Install dependencies
uv sync

# Run the CLI locally
uv run python -m quicktoken.main <file>
```
